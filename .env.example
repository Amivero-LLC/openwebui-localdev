# --- Open WebUI ---
PORT=4000
CONTAINER_NAME=open-webui
VOLUME_NAME=open-webui
IMAGE=ghcr.io/open-webui/open-webui
TAG=main

# Ollama on the host (optional)
OLLAMA_BASE_URL=http://host.docker.internal:11434

# OpenAI-compatible providers (optional)
OPENAI_API_KEY=
OPENAI_API_BASE_URLS=

# --- Docling Serve (Document Extraction) ---
# Default to CPU image for broad compatibility; change if you have GPU
DOCLING_IMAGE=ghcr.io/docling-project/docling-serve-cpu
DOCLING_TAG=latest
DOCLING_CONTAINER_NAME=docling
DOCLING_PORT=5001

# In Open WebUI UI, set Document Extraction backend to Docling at:
#   internal URL (from container): http://docling:5001
#   host URL (from your browser):  http://localhost:5001
# If enabling picture descriptions (VLM), set the model to a Hugging Face repo ID
# like "HuggingFaceTB/SmolVLM-256M-Instruct" (not a local path). The container
# will use DOCLING_ARTIFACTS_PATH for cached weights.

# --- Hugging Face cache (Approach B) ---
# Optional token if the model is gated
HUGGINGFACE_HUB_TOKEN=
# Container cache locations
HF_HOME=/opt/app-root/src/.cache/huggingface
TRANSFORMERS_CACHE=/opt/app-root/src/.cache/huggingface/hub
